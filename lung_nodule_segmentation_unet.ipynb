{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd74e1e",
   "metadata": {},
   "source": [
    "# CT-Based Lung Nodule Segmentation using 2D U-Net\n",
    "\n",
    "### Objective\n",
    "The objective of this project is to **reduce false negatives in lung cancer detection**\n",
    "by performing **pixel-level lung nodule segmentation** on CT scan slices.\n",
    "\n",
    "Since missing a malignant nodule has severe clinical consequences,\n",
    "this work **prioritizes recall (sensitivity)** over accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Highlights\n",
    "- 2D U-Netâ€“based segmentation pipeline\n",
    "- Multi-radiologist annotation fusion (union strategy)\n",
    "- Recall-optimized training and early stopping\n",
    "- Patch-based learning with padding for variable slice sizes\n",
    "- Pixel-level explainability using segmentation overlays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision numpy matplotlib tqdm opencv-python kagglehub pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8997d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0efe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: /Users/gottipalligopi/Documents/LungNoduleSegmentation/LIDC-IDRI-slices\n",
      "Patients found: 875\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.getcwd()   \n",
    "# Root directory containing LIDC-IDRI slice-wise data\n",
    "# Each patient folder contains nodule-wise subfolders with images and masks\n",
    "ROOT = os.path.join(BASE_DIR, \"LIDC-IDRI-slices\")\n",
    "\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, \"models\")\n",
    "OVERLAY_DIR = os.path.join(OUTPUT_DIR, \"overlays\")\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(OVERLAY_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Dataset root:\", ROOT)\n",
    "print(\"Patients found:\", len(os.listdir(ROOT)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f7a9c",
   "metadata": {},
   "source": [
    "## Preprocessing and Patch Extraction\n",
    "\n",
    "- Lung windowing is applied to enhance nodule visibility\n",
    "- No aggressive filtering is used to preserve subtle nodules\n",
    "- Training is performed on **128Ã—128 patches**\n",
    "- CT slices smaller than patch size are **zero-padded**, not discarded\n",
    "\n",
    "This strategy avoids data loss while supporting variable CT resolutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d0cf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lung_window(ct, center=-600, width=1500):\n",
    "    min_v = center - width // 2\n",
    "    max_v = center + width // 2\n",
    "    ct = np.clip(ct, min_v, max_v)\n",
    "    ct = (ct - min_v) / (max_v - min_v)\n",
    "    return ct.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73005781",
   "metadata": {},
   "source": [
    "## Dataset: LIDC-IDRI\n",
    "\n",
    "- Source: **LIDC-IDRI**\n",
    "- Format: Slice-wise CT images (PNG)\n",
    "- Each slice contains **up to four independent radiologist annotations**\n",
    "- Nodules are small, sparse, and often ambiguous\n",
    "\n",
    "### Annotation Handling\n",
    "To reduce false negatives caused by inter-observer variability,\n",
    "annotations from all radiologists are combined using a **union (OR)** strategy.\n",
    "\n",
    "> A pixel is considered a nodule if **any radiologist** marked it as such.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e50f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIDCDataset(Dataset):\n",
    "    def __init__(self, root_dir, patch_size=128):\n",
    "        self.samples = []\n",
    "        self.patch = patch_size\n",
    "\n",
    "        for patient in tqdm(os.listdir(root_dir)):\n",
    "            p_path = os.path.join(root_dir, patient)\n",
    "            if not os.path.isdir(p_path):\n",
    "                continue\n",
    "\n",
    "            for nodule in os.listdir(p_path):\n",
    "                case = os.path.join(p_path, nodule)\n",
    "                if not os.path.isdir(case):\n",
    "                    continue\n",
    "\n",
    "                img_dir = os.path.join(case, \"images\")\n",
    "                if not os.path.isdir(img_dir):\n",
    "                    continue\n",
    "\n",
    "                mask_dirs = [os.path.join(case, f\"mask-{i}\") for i in range(4)]\n",
    "\n",
    "                for f in sorted(os.listdir(img_dir)):\n",
    "                    if not f.endswith(\".png\"):\n",
    "                        continue   # ðŸ”‘ FIX\n",
    "\n",
    "                    # ---- Load image ----\n",
    "                    img_path = os.path.join(img_dir, f)\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is None:\n",
    "                        continue\n",
    "\n",
    "                    img = img.astype(np.float32)\n",
    "                    img = lung_window(img)\n",
    "\n",
    "                    # ---- Mask union ----\n",
    "\n",
    "                    # Combine annotations from multiple radiologists using union (OR)\n",
    "                    # A pixel is considered nodule if ANY radiologist marked it\n",
    "                    # This reduces false negatives caused by inter-observer variability\n",
    "\n",
    "                    mask_union = np.zeros_like(img, dtype=np.uint8)\n",
    "                    for md in mask_dirs:\n",
    "                        mask_path = os.path.join(md, f)\n",
    "                        if os.path.exists(mask_path):\n",
    "                            m = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                            if m is not None:\n",
    "                                mask_union |= (m > 0)\n",
    "\n",
    "                    # Skip slices without any nodule annotation\n",
    "                    # Keep even 1-pixel nodules to avoid missing subtle cancers\n",
    "                    if mask_union.sum() == 0:\n",
    "                        continue\n",
    "\n",
    "                    # ---- ensure patch fits ----\n",
    "                    if img.shape[0] < self.patch or img.shape[1] < self.patch:\n",
    "                        continue\n",
    "\n",
    "                    self.samples.append((img, mask_union.astype(np.float32)))\n",
    "\n",
    "        print(\"Total slices with nodules:\", len(self.samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.samples[idx]\n",
    "        h, w = img.shape\n",
    "\n",
    "        # Pad slices smaller than patch size instead of discarding\n",
    "        # Prevents unnecessary data loss and supports small CT resolutions\n",
    "        pad_h = max(0, self.patch - h)\n",
    "        pad_w = max(0, self.patch - w)\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            img = np.pad(\n",
    "                img,\n",
    "                ((0, pad_h), (0, pad_w)),\n",
    "                mode=\"constant\"\n",
    "            )\n",
    "            mask = np.pad(\n",
    "                mask,\n",
    "                ((0, pad_h), (0, pad_w)),\n",
    "                mode=\"constant\"\n",
    "            )\n",
    "\n",
    "        h, w = img.shape  # update after padding\n",
    "\n",
    "        # -------- SAFE RANDOM CROP --------\n",
    "        max_x = h - self.patch\n",
    "        max_y = w - self.patch\n",
    "       \n",
    "        # Random patch extraction to increase spatial diversity\n",
    "        # Ensures model does not overfit to fixed nodule locations\n",
    "        x = np.random.randint(0, max_x + 1)\n",
    "        y = np.random.randint(0, max_y + 1)\n",
    "\n",
    "        img = img[x:x+self.patch, y:y+self.patch]\n",
    "        mask = mask[x:x+self.patch, y:y+self.patch]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(img).unsqueeze(0),\n",
    "            torch.tensor(mask).unsqueeze(0)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c5efcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 875/875 [00:09<00:00, 94.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total slices with nodules: 15486\n",
      "Dataset length: 15486\n",
      "Image shape: torch.Size([1, 128, 128])\n",
      "Mask shape: torch.Size([1, 128, 128])\n",
      "Mask pixels: tensor(18.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = LIDCDataset(ROOT)\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "\n",
    "x, y = dataset[0]\n",
    "print(\"Image shape:\", x.shape)\n",
    "print(\"Mask shape:\", y.shape)\n",
    "print(\"Mask pixels:\", y.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.2\n",
    "val_size = int(len(dataset) * VAL_RATIO)\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "print(\"Val samples:\", len(val_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e944ebb",
   "metadata": {},
   "source": [
    "## Model Architecture: 2D U-Net\n",
    "\n",
    "A standard **2D U-Net** architecture is used for segmentation.\n",
    "\n",
    "### Why U-Net?\n",
    "- Encoderâ€“decoder structure captures context\n",
    "- Skip connections preserve spatial detail\n",
    "- Proven effectiveness in medical image segmentation tasks\n",
    "\n",
    "The final layer uses a **sigmoid activation** to produce a pixel-wise probability map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26891cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Standard 2D U-Net architecture\n",
    "# Encoder-decoder with skip connections for spatial detail preservation\n",
    "# Chosen due to proven effectiveness in medical image segmentation\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d1 = DoubleConv(1, 64)\n",
    "        self.d2 = DoubleConv(64, 128)\n",
    "        self.d3 = DoubleConv(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        self.u1 = DoubleConv(256+128, 128)\n",
    "        self.u2 = DoubleConv(128+64, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.d1(x)\n",
    "        c2 = self.d2(self.pool(c1))\n",
    "        c3 = self.d3(self.pool(c2))\n",
    "\n",
    "        u1 = self.up(c3)\n",
    "        u1 = self.u1(torch.cat([u1, c2], dim=1))\n",
    "\n",
    "        u2 = self.up(u1)\n",
    "        u2 = self.u2(torch.cat([u2, c1], dim=1))\n",
    "\n",
    "        return torch.sigmoid(self.out(u2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice loss is used to handle severe class imbalance\n",
    "# More suitable than cross-entropy for small object segmentation\n",
    "def dice_score(pred, target, eps=1e-6, thresh=0.35):\n",
    "    pred = (pred > thresh).float()\n",
    "    target = target.float()\n",
    "\n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2 * intersection + eps) / (pred.sum() + target.sum() + eps)\n",
    "    return dice.item()\n",
    "\n",
    "# Lower threshold used intentionally to favor recall\n",
    "# Missing a nodule (false negative) is clinically more costly than false positives\n",
    "def recall_score(pred, target, eps=1e-6, thresh=0.35):\n",
    "    pred = (pred > thresh).float()\n",
    "    target = target.float()\n",
    "\n",
    "    tp = (pred * target).sum()\n",
    "    fn = ((1 - pred) * target).sum()\n",
    "\n",
    "    recall = (tp + eps) / (tp + fn + eps)\n",
    "    return recall.item()\n",
    "\n",
    "\n",
    "def confusion_matrix_counts(pred, target, thresh=0.35):\n",
    "    pred = (pred > thresh).float()\n",
    "    target = target.float()\n",
    "\n",
    "    tp = (pred * target).sum().item()\n",
    "    fp = (pred * (1 - target)).sum().item()\n",
    "    fn = ((1 - pred) * target).sum().item()\n",
    "    tn = ((1 - pred) * (1 - target)).sum().item()\n",
    "\n",
    "    return tp, fp, fn, tn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9747511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS = 20          # upper bound\n",
    "PATIENCE = 5         # early stopping patience\n",
    "best_val_recall = 0\n",
    "patience_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde92c0c",
   "metadata": {},
   "source": [
    "## Loss Function and Training Strategy\n",
    "\n",
    "### Loss Function\n",
    "- **Dice Loss** is used to handle severe class imbalance\n",
    "- More suitable than cross-entropy for small object segmentation\n",
    "\n",
    "### False-Negativeâ€“Aware Design\n",
    "- A lower segmentation threshold (0.35) is used\n",
    "- Validation **recall** is prioritized over accuracy\n",
    "- Early stopping is based on recall improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b5e6e",
   "metadata": {},
   "source": [
    "## Early Stopping Criterion\n",
    "\n",
    "Early stopping is applied based on **validation recall**, not loss.\n",
    "\n",
    "This ensures that training stops only when the modelâ€™s ability\n",
    "to detect nodules (sensitivity) no longer improves.\n",
    "\n",
    "This choice reflects the **clinical cost of false negatives**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with recall-based early stopping\n",
    "# Validation recall is monitored instead of loss to reduce false negatives\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    # -------- TRAIN --------\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    train_bar = tqdm(\n",
    "        train_loader,\n",
    "        desc=\"Training\",\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    for x, y in train_bar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = dice_loss(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        train_bar.set_postfix(\n",
    "            loss=f\"{loss.item():.4f}\"\n",
    "        )\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # -------- VALIDATE --------\n",
    "    model.eval()\n",
    "    val_recall = 0.0\n",
    "\n",
    "    val_bar = tqdm(\n",
    "        val_loader,\n",
    "        desc=\"Validation\",\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_bar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "\n",
    "            r = recall(pred, y).item()\n",
    "            val_recall += r\n",
    "\n",
    "            val_bar.set_postfix(\n",
    "                recall=f\"{r:.4f}\"\n",
    "            )\n",
    "\n",
    "    val_recall /= len(val_loader)\n",
    "\n",
    "    # -------- EPOCH SUMMARY --------\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Recall: {val_recall:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save model only when validation recall improves\n",
    "    # Prevents overfitting while maintaining sensitivity\n",
    "    if val_recall > best_val_recall:\n",
    "        best_val_recall = val_recall\n",
    "        patience_counter = 0\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(MODEL_DIR, \"best_unet.pth\")\n",
    "        )\n",
    "        print(\"âœ“ Improved â€” model saved\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement ({patience_counter}/{PATIENCE})\")\n",
    "\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(\"ðŸ›‘ Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6576868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(MODEL_DIR, \"best_unet.pth\"), map_location=device)\n",
    ")\n",
    "model.eval()\n",
    "print(\"Best model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = dataset[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img.unsqueeze(0).to(device)).cpu()[0, 0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img[0], cmap=\"gray\")\n",
    "plt.imshow(pred > 0.35, alpha=0.4, cmap=\"Reds\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "overlay_path = os.path.join(OVERLAY_DIR, \"sample_overlay.png\")\n",
    "plt.savefig(overlay_path, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Overlay saved to:\", overlay_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0e5ab",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "The model is evaluated using **pixel-level metrics**:\n",
    "\n",
    "- **Dice Score** â€“ segmentation overlap quality\n",
    "- **Recall (Sensitivity)** â€“ ability to detect nodules\n",
    "- **Confusion Matrix (TP, FP, FN, TN)** â€“ error analysis\n",
    "\n",
    "Recall is emphasized due to the false-negativeâ€“critical nature of lung cancer detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdf45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== FINAL VALIDATION METRICS ====\n",
      "Dice Score   : 0.7314\n",
      "Recall       : 0.7597\n",
      "\n",
      "Confusion Matrix (pixel-level):\n",
      "TP: 377968.0\n",
      "FP: 126516.0\n",
      "FN: 120963.0\n",
      "TN: 50115801.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "total_dice = 0.0\n",
    "total_recall = 0.0\n",
    "\n",
    "TP = FP = FN = TN = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "\n",
    "        # Dice & Recall\n",
    "        total_dice += dice_score(pred, y)\n",
    "        total_recall += recall_score(pred, y)\n",
    "\n",
    "        # Confusion matrix\n",
    "        tp, fp, fn, tn = confusion_matrix_counts(pred, y)\n",
    "        TP += tp\n",
    "        FP += fp\n",
    "        FN += fn\n",
    "        TN += tn\n",
    "\n",
    "# Average scores\n",
    "avg_dice = total_dice / len(val_loader)\n",
    "avg_recall = total_recall / len(val_loader)\n",
    "\n",
    "\n",
    "# Final evaluation performed using Dice, Recall, and Confusion Matrix\n",
    "# Metrics reported at pixel level\n",
    "print(\"==== FINAL VALIDATION METRICS ====\")\n",
    "print(f\"Dice Score   : {avg_dice:.4f}\")\n",
    "print(f\"Recall       : {avg_recall:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (pixel-level):\")\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(f\"TN: {TN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476250cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Nodule</th>\n",
       "      <th>Predicted Background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Nodule</th>\n",
       "      <td>377968.0</td>\n",
       "      <td>126516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Background</th>\n",
       "      <td>120963.0</td>\n",
       "      <td>50115801.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Nodule  Predicted Background\n",
       "Actual Nodule              377968.0              126516.0\n",
       "Actual Background          120963.0            50115801.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    [[TP, FP],\n",
    "     [FN, TN]],\n",
    "    columns=[\"Predicted Nodule\", \"Predicted Background\"],\n",
    "    index=[\"Actual Nodule\", \"Actual Background\"]\n",
    ")\n",
    "\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ae916",
   "metadata": {},
   "source": [
    "## Results and Interpretation\n",
    "\n",
    "Final validation performance:\n",
    "\n",
    "- **Dice Score:** 0.73\n",
    "- **Recall:** 0.76\n",
    "\n",
    "These results indicate strong sensitivity to lung nodules while maintaining\n",
    "reasonable segmentation quality.\n",
    "\n",
    "The Dice score reflects realistic performance given:\n",
    "- Small nodule size\n",
    "- Sparse annotations\n",
    "- Inter-observer variability in LIDC-IDRI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
